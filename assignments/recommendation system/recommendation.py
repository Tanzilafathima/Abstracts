# -*- coding: utf-8 -*-
"""recommendation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12lm61ODMl6cJqhCCdNZ9wMeuUPdARSMG
"""

pip install surprise

from google.colab import files
uploaded=files.upload()

import numpy as np
import pandas as pd
from surprise.model_selection import train_test_split
from surprise.model_selection import cross_validate
from surprise.model_selection import KFold
from surprise import NormalPredictor
from surprise import BaselineOnly
from surprise import KNNBasic
from surprise import KNNWithMeans
from surprise import KNNBaseline
from surprise import SVD
from surprise import SVDpp
from surprise import NMF
import surprise
from surprise import SlopeOne
from surprise import CoClustering
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score #works

df=pd.read_csv("bookrecommendation.csv")
df

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import pairwise_distances
from scipy.spatial.distance import cosine, correlation

df1 = df.iloc[:,1:]
df1.columns = ['userID', 'title', 'bookRating']
df1.head()

print('# of records: %d\n# of books: %d\n# of users: %d' % (len(df1), len(df1['title'].unique()), len(df1['userID'].unique())))

palette = sns.color_palette("RdBu", 10)

fig, ax = plt.subplots(figsize=(10, 6))
sns.countplot(x='bookRating', data=df1, palette=palette)
ax.set_title('Distribution of book ratings')

plt.show()

"""The majority of ratings is between 5 and 10. Most often users tend to rate books for 8. Second the most frequent score is 7.

3 - Introduction to "Surprice" Package
"""

df1.bookRating.unique()

reader = surprise.Reader(rating_scale=(1, 10))
data = surprise.Dataset.load_from_df(df1[['userID', 'title', 'bookRating']], reader)
trainset, testset = train_test_split(data, test_size=.20)

"""4 - Finding the best algorithm for our Recommendation System"""

benchmark = []
for algorithm in [SVD(), SVDpp(), SlopeOne(), NMF(), NormalPredictor(), KNNBaseline(), KNNBasic(), KNNWithMeans(), BaselineOnly(), CoClustering()]:
    results = cross_validate(algorithm, data, measures=['RMSE'], cv=3, verbose=False)
    tmp = pd.DataFrame.from_dict(results).mean(axis=0)
    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))
    benchmark.append(tmp)

pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')

"""SVD () algorithm gave us the best rmse, therefore, we will train and predict with SVD

5 - Building our Recommendation System using surprice
"""

algo = SVD()
algo.fit(trainset)

predictions = algo.test(testset)
accuracy.rmse(predictions, verbose=True)

